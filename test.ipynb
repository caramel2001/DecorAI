{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export REPLICATE_API_TOKEN=r8_OowioSTEHuawUOZ01mRiYqBKVmT3dv14Bnnfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set os varibale \n",
    "import os\n",
    "os.environ['REPLICATE_API_TOKEN'] =\"r8_OowioSTEHuawUOZ01mRiYqBKVmT3dv14Bnnfa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReplicateError",
     "evalue": "You did not pass an authentication token",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReplicateError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/pratham/Desktop/23S1/developing data products/DecorAI/test.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m output \u001b[39m=\u001b[39m replicate\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mjagilley/controlnet-hough:854e8727697a057c525cdb45ab037f64ecca770a1769cc52287c2e56472a247b\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m{\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39meta\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m0\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mhttps://replicate.delivery/pbxt/IJZOELWrncBcjdE1s5Ko8ou35ZOxjNxDqMf0BhoRUAtv76u4/room.png\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mscale\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m9\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39ma cheerful modernist bedroom\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39ma_prompt\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mbest quality, extremely detailed\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mn_prompt\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mlongbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mddim_steps\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m20\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mnum_samples\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mvalue_threshold\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m0.1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mimage_resolution\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39m512\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mdetect_resolution\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m512\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mdistance_threshold\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m0.1\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(output)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/streamlit/lib/python3.9/site-packages/replicate/client.py:148\u001b[0m, in \u001b[0;36mClient.run\u001b[0;34m(self, ref, input, **params)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\n\u001b[1;32m    139\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    140\u001b[0m     ref: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    141\u001b[0m     \u001b[39minput\u001b[39m: Optional[Dict[\u001b[39mstr\u001b[39m, Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    142\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams: Unpack[\u001b[39m\"\u001b[39m\u001b[39mPredictions.CreatePredictionParams\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    143\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Any, Iterator[Any]]:  \u001b[39m# noqa: ANN401\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39m    Run a model and wait for its output.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m     \u001b[39mreturn\u001b[39;00m run(\u001b[39mself\u001b[39;49m, ref, \u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/streamlit/lib/python3.9/site-packages/replicate/run.py:40\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(client, ref, input, **params)\u001b[0m\n\u001b[1;32m     37\u001b[0m version, owner, name, version_id \u001b[39m=\u001b[39m identifier\u001b[39m.\u001b[39m_resolve(ref)\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m version_id \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     prediction \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mpredictions\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     41\u001b[0m         version\u001b[39m=\u001b[39;49mversion_id, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m \u001b[39mor\u001b[39;49;00m {}, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m \u001b[39melif\u001b[39;00m owner \u001b[39mand\u001b[39;00m name:\n\u001b[1;32m     44\u001b[0m     prediction \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mpredictions\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m     45\u001b[0m         model\u001b[39m=\u001b[39m(owner, name), \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39minput\u001b[39m \u001b[39mor\u001b[39;00m {}, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m     46\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/streamlit/lib/python3.9/site-packages/replicate/prediction.py:364\u001b[0m, in \u001b[0;36mPredictions.create\u001b[0;34m(self, version, input, **params)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mCreate a new prediction for the specified model version.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    359\u001b[0m body \u001b[39m=\u001b[39m _create_prediction_body(\n\u001b[1;32m    360\u001b[0m     version,\n\u001b[1;32m    361\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[1;32m    362\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    363\u001b[0m )\n\u001b[0;32m--> 364\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    365\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    366\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m/v1/predictions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    367\u001b[0m     json\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    368\u001b[0m )\n\u001b[1;32m    370\u001b[0m \u001b[39mreturn\u001b[39;00m _json_to_prediction(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client, resp\u001b[39m.\u001b[39mjson())\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/streamlit/lib/python3.9/site-packages/replicate/client.py:86\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, method, path, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_request\u001b[39m(\u001b[39mself\u001b[39m, method: \u001b[39mstr\u001b[39m, path: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m httpx\u001b[39m.\u001b[39mResponse:\n\u001b[1;32m     85\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mrequest(method, path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 86\u001b[0m     _raise_for_status(resp)\n\u001b[1;32m     88\u001b[0m     \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/streamlit/lib/python3.9/site-packages/replicate/client.py:359\u001b[0m, in \u001b[0;36m_raise_for_status\u001b[0;34m(resp)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_for_status\u001b[39m(resp: httpx\u001b[39m.\u001b[39mResponse) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m400\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m resp\u001b[39m.\u001b[39mstatus_code \u001b[39m<\u001b[39m \u001b[39m600\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m         \u001b[39mraise\u001b[39;00m ReplicateError(resp\u001b[39m.\u001b[39mjson()[\u001b[39m\"\u001b[39m\u001b[39mdetail\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mReplicateError\u001b[0m: You did not pass an authentication token"
     ]
    }
   ],
   "source": [
    "output = replicate.run(\n",
    "    \"jagilley/controlnet-hough:854e8727697a057c525cdb45ab037f64ecca770a1769cc52287c2e56472a247b\",\n",
    "    input={\n",
    "        \"eta\": 0,\n",
    "        \"image\": \"https://replicate.delivery/pbxt/IJZOELWrncBcjdE1s5Ko8ou35ZOxjNxDqMf0BhoRUAtv76u4/room.png\",\n",
    "        \"scale\": 9,\n",
    "        \"prompt\": \"a cheerful modernist bedroom\",\n",
    "        \"a_prompt\": \"best quality, extremely detailed\",\n",
    "        \"n_prompt\": \"longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality\",\n",
    "        \"ddim_steps\": 20,\n",
    "        \"num_samples\": \"1\",\n",
    "        \"value_threshold\": 0.1,\n",
    "        \"image_resolution\": \"512\",\n",
    "        \"detect_resolution\": 512,\n",
    "        \"distance_threshold\": 0.1\n",
    "    }\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/pratham/Desktop/23S1/developing data products/DecorAI/test.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pratham/Desktop/23S1/developing%20data%20products/DecorAI/test.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m structural_similarity \u001b[39mas\u001b[39;00m ssim\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Download YOLOv3 weights and configuration file\n",
    "!wget https://pjreddie.com/media/files/yolov3.weights\n",
    "!wget https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg?raw=true -O yolov3.cfg\n",
    "!wget https://github.com/pjreddie/darknet/blob/master/data/coco.names?raw=true -O coco.names\n",
    "\n",
    "# Load COCO class labels\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f]\n",
    "\n",
    "def object_detection(image_path, furniture_classes=[\"bed\", \"sofa\", \"diningtable\"]):\n",
    "    # Use PIL to read the image\n",
    "    img = Image.open(image_path)\n",
    "    img = np.array(img)  # Convert PIL Image to NumPy array\n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            \n",
    "            # Get the class label from the COCO class labels file (coco.names)\n",
    "            label = classes[class_id]\n",
    "\n",
    "            # Only keep objects related to furniture\n",
    "            if label.lower() in furniture_classes and confidence > 0.5:\n",
    "                center_x, center_y, w, h = (detection[0:4] * np.array([width, height, width, height])).astype('int')\n",
    "                x, y = int(center_x - w / 2), int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    return boxes, confidences, class_ids\n",
    "\n",
    "# Load YOLOv3 model\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Example usage:\n",
    "input_image_path = \"/content/room_image.jpg\"  # Replace with the correct file path\n",
    "boxes, _, _ = object_detection(input_image_path)\n",
    "\n",
    "# Visualize bounding boxes on the input image\n",
    "image = cv2.imread(input_image_path)\n",
    "for box in boxes:\n",
    "    x, y, w, h = box\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite(\"output_image.jpg\", image)\n",
    "\n",
    "\n",
    "\n",
    "!mkdir extracted_boxes\n",
    "\n",
    "\n",
    "\n",
    "def extract_labeled_boxes(image_path, boxes, class_ids, classes, output_folder=\"extracted_boxes\"):\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for i, (box, class_id) in enumerate(zip(boxes, class_ids)):\n",
    "        x, y, w, h = box\n",
    "        object_image = img[y:y + h, x:x + w]\n",
    "        label = classes[class_id]\n",
    "\n",
    "        # Save the image with the corresponding label\n",
    "        cv2.imwrite(f\"{output_folder}/{label}object{i}.jpg\", object_image)\n",
    "\n",
    "def object_detection_with_visualization(image_path, output_folder=\"output_images\"):\n",
    "    img = Image.open(image_path)\n",
    "    img_np = np.array(img)\n",
    "    height, width, _ = img_np.shape\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img_np, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if confidence > 0.5:\n",
    "                center_x, center_y, w, h = (detection[0:4] * np.array([width, height, width, height])).astype('int')\n",
    "                x, y = int(center_x - w / 2), int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Draw bounding boxes and labels on the image\n",
    "    for i, box in enumerate(boxes):\n",
    "        x, y, w, h = box\n",
    "        label = classes[class_ids[i]]\n",
    "        cv2.rectangle(img_np, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(img_np, f\"{label} {confidences[i]:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Save the image with bounding boxes and labels\n",
    "    output_path = os.path.join(output_folder, \"output_image.jpg\")\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR))\n",
    "    print(f\"Visualized image saved at: {output_path}\")\n",
    "\n",
    "    return boxes, confidences, class_ids\n",
    "\n",
    "# Example usage:\n",
    "input_image_path = \"/content/room_image.jpg\"  # Replace with the correct file path\n",
    "boxes, _, class_ids = object_detection_with_visualization(input_image_path)\n",
    "\n",
    "# Extract labeled objects from the image\n",
    "extract_labeled_boxes(input_image_path, boxes, class_ids, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
